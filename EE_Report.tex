\documentclass[12pt,a4paper]{article}

% Essential packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[english]{babel}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}
\usepackage[margin=2.5cm]{geometry}
\usepackage{setspace}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{adjustbox}
\usepackage{siunitx}
\usepackage{float}
\usepackage[hidelinks]{hyperref}
\usepackage{xcolor}
\usepackage{colortbl}

% Page setup
\onehalfspacing
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{K-Epsilon CFD Analysis}
\fancyhead[R]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}

% Title formatting
\titleformat{\section}{\large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{1em}{}
\titleformat{\subsubsection}{\normalsize\bfseries}{\thesubsubsection}{1em}{}

% Table setup
\renewcommand{\arraystretch}{1.1}
\setlength{\tabcolsep}{4pt}

% Custom colors for tables (matching original)
\definecolor{lightblue}{RGB}{207,226,243}
\definecolor{mediumblue}{RGB}{159,197,232}
\definecolor{darkblue}{RGB}{61,133,198}
\definecolor{navyblue}{RGB}{11,83,148}
\definecolor{lightgreen}{RGB}{0,255,0}
\definecolor{red}{RGB}{255,0,0}

\begin{document}

% Title Page
\begin{titlepage}
\centering
\vspace*{2cm}
{\LARGE\bfseries Analysis of K-Epsilon Computational Model in ANSYS:\\[0.5cm] 
Impact of Mesh Density and Iterations on Turbulent Flow Prediction Accuracy for Complex Geometries}\\[2cm]

{\large A Research Investigation into Computational Fluid Dynamics}\\[1.5cm]

{\large Submitted by: [Student Name]}\\[0.5cm]
{\large Student ID: [Student ID]}\\[0.5cm]
{\large Course: [Course Code]}\\[0.5cm]
{\large Institution: [University Name]}\\[1.5cm]

{\large Date: \today}\\[2cm]

\vfill
\end{titlepage}

% Table of Contents
\newpage
\tableofcontents
\newpage

% List of Figures
\listoffigures
\newpage

% List of Tables
\listoftables
\newpage

\section{Introduction}

\subsection{Aims and Objectives}

In the k-epsilon computational model in ANSYS how does the time invested into calculation heavy mesh and iteration affect the accuracy of prediction of turbulent flow characteristic fpr complex geometries?

In this experiment I will try and compare diffrent simulation set ups, so diffrent mesh densities and amounts of itterations, against experimental values of drag coefficeance found experimentaly. Through this I try to evalute how accurate simulations can get or should get in reference to the values obtained in the wing tunnel.

Now it might seem like I have two depend variables and two independent, but actually I am measuring the wasted time from simulating for no accuracy benefit created by the variables instead, I need both of them to understand what is actually waisting the time. I am measuring the time waisted, because our computers are consuming powers in watt, which means the longer the simulation takes the more power is consumed, assuming the time is wasted because the simulation is not getting more accurate as I stated this would mean the power is wasted aswell. This ofcourse requires the assumption that all computtions did require the same power.

\subsection{Background}

\subsubsection{IB Fluid Drag Formula}

TheIBsupplies a simplified equation and theory behind fluid drags on objects, $F_{drag} = 6\pi\eta rv$, which assumes all objects are round, and flow is laminar, this creates allot of limitations which simulations eliminate.

\subsubsection{Computational Fluid Dynamics (CFD)}

Computational fluid dynamics simulations are computer simulations of fluid flow. They are used to analyse and solve problems in fluid flow, heat transfer and similar activities. They rely on heavy software and computational power to simulate difficult situations which are hard to simulate experimentally. 

It involves a lot of physics equations, especially the Navier stokes and the Reynolds equations, to calculate pressure velocity, temperature, and density of a fluid over time in different situations, from which drag can also be calculated. It is very important in various industries: Aerodynamics (e.g., aircraft design, drag reduction), Automotive engineering (e.g., optimizing car shapes for fuel efficiency), Energy (e.g., modeling wind turbines, heat exchangers), Medicine (e.g., studying blood flow in arteries).

\subsubsection{K-Epsilon Model}

CFD simulations run on different models, the model that I am choosing is the K-epsilon model, it is a very popular model used in a lot of amateur and beginner simulations, which don't require a niche model.

The k-episode model was developed by Launder and Spalding in 1974 to improve on older models like the mixing length model. It offers a more general and practical approach to modeling complex turbulence and flows. It majorly uses two equations, one for turbulent kinetic energy and one for dissipation rates.

This model is often used in simulating airflows in HVAC systems and combustion in engines, analysing drag and lift on vehicles, Modeling the travel of particles like pollutant through water and the atmosphere and studying flow in pipes, channels and bridges

The model predicts the mean flow characteristics of flows, by solving the two equations, it is assuming isotropic turbulence, which means the turbulent viscosity is equal across every direction, this makes it very suitable for many engineering applications. Though It does struggle with the investigated complex geometries.

\subsubsection{Why is the K-Epsilon Model Good?}

Because the model only uses two equations to calculate the simulation its simplisity matches its power. It is great for a wide range of reynolds number of flows, so it is perfect for simulating turbulence. The model shows to converge correctly, in simulation converging is referred to when multible sennerios and calculations give the same answer which means the simulation has finished. And as the model has been used since 1974 it has had decates of testing, impovements and validation

There are better models out ther now like the k-omega sst, which can handle bigger pressure drops accros the simulation, but that model is even more power hungry and expensive to run. The k-epsilon model is not very good at calculating swirls and flows including strong separation in the fluid.

\subsubsection{Why is ANSYS Good?}

I am using a student version of the ANSYS software which is running all the simulations, ANSYS is such a good choice, because it has incredible horizon of simulation choices, it offers more then just fluid dynamics, but it can also simulate things like heat transfer and electromagnetic fields. This makes it very appealing for engineers. 

Over 17.000 companies use asyns, including racign and rocket teams liek NASA and redbull racing.,Proving acceptance. 

\subsubsection{Mesh Density}

This investigation is investigating the affect of mesh density on time, now why does mesh density actually matter?

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{image9.png}
    \caption{Mesh visualization of a complex geometry showing triangular elements with varying density}
    \label{fig:mesh_example}
\end{figure}

above is a image of the mesh of one of the complex objects simulated in the experiment. Mesh density can metaphorically be refferet to as resolution, every one of the triangles above is a pixel on A screen, the more triangles your have per area like in the middle right of the image the better the resolution. A simulation calculates the physical behavior of every triangle. Particles are very small which all follow the laws of physics, and the closer the triangles get to the size of the particle the more accurate does the simulation get, but that also means more calculations need to be doen, and possible more time will be allocated to the simulation.

\subsubsection{Why does the Amount of Iterations Matter?}

In simulation iterations refers to the amount of scenarios,The scenarios refer to testing different temperatures, velocities and pressure in different places. for which all calculations are done. Like in statistics the bigger the sample size the smaller the random error. And the standart diviation of all findings will get smaller aswell. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{image8.png}
    \caption{Simulated drag results versus iteration number showing convergence behavior}
    \label{fig:convergence}
\end{figure}

In the graph above, I have displayed the simulated drag results y against the amount of iterations x, visible is that after 20 itterations the simulated drag is not really changing this is reffered to as converging. But before testing all scenarios its uncertain if the values will change, so there is a incentive to have almost infinite amount of itterations. But for every itteration a complete calculation of all physical behaviours needs to be done. so more itterations mean more time.

\subsubsection{Residuals}

One of the constants of this investigation is residuals, residuals govern how far the simulation will run until the values converge. they do this by reflecting the imbalance in the conservation laws, mass enegyâ€¦, in the navier stokes equations, low residulas means more pressice measurements and high residuals mean low precition. The residuals therefore basically define too how many significant figures the calculation are hold truthfully, the experiment has all residuals defined to 5 digit accuracy, because when running tests at 6 digit accuracy, the test did not converge even after 1000 itteration and as seen in the graph above for the iterations this means the simulations could have taken even longer and return no relativly more valueble insights. 

All simulations in this experiment are run to either all residuals converge, which means the number calculated is the number the computer thinks is most accurate, or to 1000 itteration, because that can indicate that there is a error with the geometry or the mesh of the simulation and the simulations is likely faulted, or and can not get more accurate.


\section{Literature Review}

\subsection{The Physics of Fluid Flow}

IB assumes fully laminar flow, for engeering this assumption might not result in pleasing result. Because laminar flow only happens in very viscous fluids or in very stream line bodies. In refrence to fluid drag this means only drag in the form of skin friction will get calculated.

Turbulent flow means the the fluid creates chaotic and swirling eddies, for egneniers turbulent flow is often very real. It applies at high velocities or when the geometry are more complex and the viscosity of fluids is low liek air. In reference to fluid drag turbulence introduces new kinds of drag like pressure drag, this drag is created when the eddies create flow separation allongsaide the object, so turbulent calculations need to consider the stream lines of objects, referred to as cd, theIBformula does not consider this at all and only considers drag created directly on the front face of the objects. 

\subsection{Computational Fluid Dynamics (CFD)}

The k epsilon model uses two equations to calculate the physical behaviour of particles.
the navier stokes equation: 
\begin{align}
\text{Continuity: } \nabla \cdot \vec{u} &= 0\\
\text{Momentum: } \rho\left(\frac{\partial \vec{u}}{\partial t} + \vec{u} \cdot \nabla \vec{u}\right) &= -\nabla p + \mu \nabla^2 \vec{u} + \vec{f}
\end{align}

Is what physicist would use to do such calculations, the IB fluid drag formula uses a simplification of this formula, because the equations are nonlinear and interdependent it is very difficult to calculate specific behaviour especially when turbulent flow is introduced, for the same reason the k-epsilon model actually also uses a simplicication of this equation aswell.

The model uses the reynolds average stokes equations,
\begin{equation}
\rho\left(\frac{\partial \overline{u_i}}{\partial t} + \overline{u_j}\frac{\partial \overline{u_i}}{\partial x_j}\right) = -\frac{\partial \overline{p}}{\partial x_i} + \mu\frac{\partial^2 \overline{u_i}}{\partial x_j^2} - \frac{\partial \rho\overline{u_i' u_j'}}{\partial x_j}
\end{equation}

This equation introduces turbulence and averages the stokes equations making it possible to calculate the behavoir of particles,  this equation is viewing mean and fluctuating variables at the same time, this means that from the mesh picture the surrounding triangles also affect the individuel triangle, very muhc like how all particle affect each other.

\section{Methodology}

\subsection{Experimental Approach}

The value I am finding through the simulation, will be compared to a highly extensive researched database.

\subsection{Computational Simulation}

Using ANSYS, a computer simulation software, the drag forces experienced by the objects will be simulated. I will be changin two variables to see the affect on the accuracy of the simulation outcome and how long the simulation needs to finish, Mesh density and the amount of iterations, because I predicted them to have the biggest impact on the time taken for the simulations to finish. I will use this formula $F_d = \frac{c_d \rho u^2 A}{2}$ to compare my simulated drags forces, to forces I calculated using the Cd aquired experimentaly. 

To be sure that all other variables are sensible I have set them as follows. The air speed at which the drag will be simulated will be 100ms$^{-1}$, this is because drag will increase significantly at close to mock numbers due to the increased pressure of the schock cone, but the drag at low velocity is very small and sometimes insignificant, exactly what value is chosen is not important, as long it is constant in the comparison calculations. 

I have set the air density used in the simulation to 1.225 kgm$^{-3}$ which is the standart setting in ANSYS, but is also standart air pressure, this variable could also be changed, it just needs to be constant in the comparison though.

 I have set the area of the geometries facing the air stream to be equal to 1m$^2$; although also this value is arbitrary, I think using 1m$^2$ will be helpful in the future, when making predictions on other geometries, as it is base one.

I will be testing different mesh densities, which I calculate by the number of mesh elements divided by the volume of the perimeter in which the simulation is taking place, as that volume is also constant across all simulations I will refer to the mesh only by the amount of elements.

I am not changing the total amounts of mesh elements directly, instead I am changing the size of the elements close to the object. This is common use and is useful, because I would not expect allot of physics behaviour far away from the geometrie for which I want to calculate the drag, 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{image1.png}
    \caption{Flow visualization showing physics behavior primarily near the cube geometry}
    \label{fig:flow_viz}
\end{figure}

As seen above the flow is mostly just red further away from the cube, this indicated that there is no physics behaviour happing there. I have labelled the msot dense mesh 5 and the least dense mesh 1, from my hypothesis I would expect Mesh 5 to take the longest and have the most accurate results, although not significantly more accurate then 3 or 4. 

The general mesh size of the simulation parameters is 1 m$^3$, this means that calculations are done for that 1 m$^3$ and the simulation assumes one particle has the size of 1 m$^3$ and it will calculate a mean physics behaviour for that whole area. I have set the most accurate mesh elements to be 0.05m$^3$ big directly next to the geometries, this is significantly smaller than both the general mesh size and the geometrie, so it should give accrued calculation results. Because if we go back to the screen analagie, it is only possible to show a elephant for example if the pixels are smaller than the elephant which I am trying to display, in this case the mesh element size is smaller then the geometry so it should be possible to simulate it.

\begin{table}[H]
\centering
\caption{Mesh configuration for cube geometry}
\label{tab:mesh_config}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\rowcolor{red!50}
\textbf{Mesh} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} \\
\hline
element size /m & 0.25 & 0.2 & 0.15 & 0.1 & 0.05 \\
\hline
number of elements & 52168 & 68605 & 97258 & 153590 & 341044 \\
\hline
\end{tabular}
\end{table}

In the last row I have writin the total amount of elements, this number is not significant, I can not change it directly I can only impact the element size, the number of elements is only what I can measure, I will get back to size, but because the element sizes are used equally across all geometries to get a more accurate comparison I wiil use the amount of elements which arent equal across all geometries later for comparison. This is because some geometries might take less time to simulate and be less accurate eventhough they have same mesh size, because they are smaller by themselves, I have to scale all objects to have a frontal area of 1 m$^2$, but some objects are longer than others. For every mesh size I will run the simulation again, I will then write down the total number of iterations the simulations hade to do before converging, if the simulation never converged I have capped the maximum number of iterations at 1000, then I will take readings of the drag force at every 1/5 amount of all iterations, this should give me some kind of understanding, how the accuracy is changing over the run of the experiment.

\begin{table}[H]
\centering
\caption{Example of iteration documentation, for the mesh3 of the cube}
\label{tab:iteration_example}
\begin{tabular}{|>{\centering\arraybackslash}p{0.1666\linewidth}|>{\centering\arraybackslash}p{0.1666\linewidth}|>{\centering\arraybackslash}p{0.1666\linewidth}|>{\centering\arraybackslash}p{0.1666\linewidth}|}
\hline
\rowcolor{red!50}
\textbf{total Iterations} & \textbf{218} &  &  \\
\hline
\textbf{1/5 of total Iterations} & \textbf{2/5 of total Iterations} & \textbf{3/5 of total Iterations} & \textbf{4/5 of total Iterations} \\
\hline
44 & 87 & 131 & 174 \\
\hline
\end{tabular}
\end{table}

\[
\frac{\text{Total Iterations}}{\text{Steps}} = \frac{218}{5} = 43.6 \approx 44
\]

\section{Results and Discussion}

\subsection{Experimental Results}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{image8.png}
    \caption{Simulation monitoring display during runtime}
    \label{fig:simulation_display}
\end{figure}

This is what I can view when the simulation is running, already from this one can see that nothing really changes allot in the run of the simulation. Not every graph looked as clear as this one for the cube.

\begin{table}[H]
\centering
\caption{Full data collected for the cube simulation}
\label{tab:cube_results}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\rowcolor{lightblue}
\textbf{Iteration} & \textbf{Expected /N} & \textbf{Mesh 1 /N} & \textbf{\% error} & \textbf{Mesh 2 /N} & \textbf{\% error} & \textbf{Mesh 3 /N} & \textbf{\% error} & \textbf{Mesh 4 /N} & \textbf{\% error} & \textbf{Mesh 5 /N} & \textbf{\% error} \\
\hline
1/5 of total & 6.43E+03 & 5.72E+03 & 11.01\% & 5.98E+03 & 6.96\% & 6.07E+03 & 5.67\% & 6.23E+03 & 3.19\% & 6.04E+03 & 6.04\% \\
\hline
2/5 of total & 6.43E+03 & 5.72E+03 & 11.04\% & 5.97E+03 & 7.15\% & 6.08E+03 & 5.47\% & 6.30E+03 & 2.08\% & 6.38E+03 & 0.84\% \\
\hline
3/5 of total & 6.43E+03 & 5.72E+03 & 11.01\% & 5.97E+03 & 7.20\% & 6.10E+03 & 5.22\% & 6.30E+03 & 2.02\% & 6.42E+03 & 0.18\% \\
\hline
4/5 of total & 6.43E+03 & 5.73E+03 & 10.97\% & 5.97E+03 & 7.19\% & 6.09E+03 & 5.26\% & 6.30E+03 & 2.00\% & 6.43E+03 & 0.07\% \\
\hline
5/5 of total & 6.43E+03 & 5.72E+03 & 10.99\% & 5.97E+03 & 7.17\% & 6.09E+03 & 5.29\% & 6.30E+03 & 2.01\% & 6.43E+03 & 0.06\% \\
\hline
\end{tabular}
}
\end{table}
\[
\text{Expected }  F_d = \frac{c_d \, \rho \, u^2 \, A}{2} = \frac{1.05 \times 1.225 \times (100)^2 \times 1}{2} = 6431.25 \, \text{N}
\]

\[
\text{\% Error} = 1 - \frac{\text{Expected}}{\text{Simulated}} = 1 - \frac{6431.25}{5723.3} \approx 0.1101 = 11.01\%
\]

\[
c_d^{\text{cube}} = 1.05 \quad \text{[1]}
\]
This is the table of measurements found for the cube. Now we can see that  after the simulations finished so after all iterations, and with the highest mesh density, the simulation has found accurate forces up to 99.94\% also to be seen is that atleast until â…— of the total simulation the accuracy was already atleast 99.93\% so one might say that the simulation did not need to be completed that long, this error is smaller than the significant figures in my database. Even the 2 \% error from the less dense mesh is accurate enough to make predictions instead of using a air tunnel. 

The computer seems to find it more difficult to start calculating complex meshes, because in the more dense meshes the start of the simulation gives far different values than the end does, this difference decrease in less dense meshes, but this is also because measurements for those meshes where taken at iterations, whichs absolut number of iterations was smaller.

\begin{table}[H]
\centering
\caption{Amount of mesh elements versus average error for cube simulation}
\label{tab:cube_elements_error}
\begin{tabular}{|c|c|}
\hline
\rowcolor{lightblue}
\textbf{Amount of mesh elements} & \textbf{\% avg. error}\\
\hline
52168 & 11.00\% \\
\hline
68605 & 7.13\% \\
\hline
97258 & 5.38\% \\
\hline
153590 & 2.26\% \\
\hline
341044 & 1.44\% \\
\hline
\end{tabular}
\end{table}

\[
\text{Avg.\% Error} = \frac{11.01\% + 11.04\% + 11.01\% + 10.97\% + 10.99\%}{5} = \frac{55.02\%}{5} = 11.00\%
\]

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{image14.png}
\caption{Average \%error against amount of mesh elements for the cube}
\label{fig:cube_elements_error}
\end{figure}

I have choosen to grapght the percentage error of each Mesh interval against the total number of Mesh elements, to view how Error is decreasing with increaseing amount of mesh elements. mesh elements varie from Geometry to Geometry, so this allows comparisonts.

\begin{table}[H]
\centering
\caption{Amount of mesh elements versus error for cube simulation}
\label{tab:cube_elements_error}
\begin{tabular}{|c|c|}
\hline
\rowcolor{lightblue}
\textbf{avg. iteration number}& \textbf{\% error} \\
\hline
103& 6.57\%\\
\hline
206& 5.31\%\\
\hline
308& 5.13\%\\
\hline
411& 5.10\%\\
\hline
514& 5.10\%\\
\hline
\end{tabular}
\end{table}
\[
\text{Avg. Error} = \frac{11.01\% + 6.96\% + 5.67\% + 3.19\% + 6.04\%}{5}= 6.574\% \approx 6.57\%
\]
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Bildschirmfoto 2025-08-24 um 14.13.37.png}
    \caption{Average percentage error against average amount of iterations for cube}
    \label{fig:cube_iterations_error}
\end{figure}

Figure \ref{fig:cube_iterations_error} This graph compares how the percentage error decreases, as the average amount of iterations is increasing. this graph is very use full, because it can compare against simulations, which both did not converge, and converged early.

\subsection{Results for Other Geometries}

\subsubsection{Cone Results}

\begin{table}[H]
\centering
\caption{Complete data collected for cone simulation}
\label{tab:cone_results}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\rowcolor{lightblue}
\textbf{Iteration} & \textbf{Expected (N)} & \textbf{Mesh 1 (N)} & \textbf{\% error} & \textbf{Mesh 2 (N)} & \textbf{\% error} & \textbf{Mesh 3 (N)} & \textbf{\% error} & \textbf{Mesh 4 (N)} & \textbf{\% error} & \textbf{Mesh 5 (N)} & \textbf{\% error} \\
\hline
1/5 of total & 3.06E+03 & 3.98E+03 & -30.01\% & 3.98E+03 & -30.05\% & 3.96E+03 & -29.26\% & 4.05E+03 & -32.39\% & 3.73E+03 & -21.86\% \\
\hline
2/5 of total & 3.06E+03 & 3.92E+03 & -27.99\% & 3.92E+03 & -27.91\% & 3.92E+03 & -27.99\% & 3.86E+03 & -25.90\% & 3.64E+03 & -18.76\% \\
\hline
3/5 of total & 3.06E+03 & 3.92E+03 & -27.93\% & 3.92E+03 & -27.87\% & 3.92E+03 & -28.00\% & 3.85E+03 & -25.63\% & 3.63E+03 & -18.39\% \\
\hline
4/5 of total & 3.06E+03 & 3.92E+03 & -27.92\% & 3.92E+03 & -27.85\% & 3.92E+03 & -28.00\% & 3.85E+03 & -25.59\% & 3.62E+03 & -18.34\% \\
\hline
5/5 of total & 3.06E+03 & 3.92E+03 & -27.91\% & 3.92E+03 & -27.85\% & 3.92E+03 & -28.00\% & 3.85E+03 & -25.59\% & 3.62E+03 & -18.34\% \\
\hline
\end{tabular}
}
\end{table}

\subsubsection{Half Sphere Results}

\begin{table}[H]
\centering
\caption{Complete data collected for half sphere simulation}
\label{tab:half_sphere_results}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\rowcolor{lightblue}
\textbf{Iteration} & \textbf{Expected (N)} & \textbf{Mesh 1 (N)} & \textbf{\% error} & \textbf{Mesh 2 (N)} & \textbf{\% error} & \textbf{Mesh 3 (N)} & \textbf{\% error} & \textbf{Mesh 4 (N)} & \textbf{\% error} & \textbf{Mesh 5 (N)} & \textbf{\% error} \\
\hline
1/5 of total & 7.17E+03 & 7.44E+03 & -3.84\% & 8.06E+03 & -12.43\% & 8.27E+03 & -15.42\% & 7.40E+03 & -3.26\% & 7.37E+03 & -2.91\% \\
\hline
2/5 of total & 7.17E+03 & 7.44E+03 & -3.85\% & 7.31E+03 & -1.98\% & 7.52E+03 & -4.94\% & 7.40E+03 & -3.32\% & 7.32E+03 & -2.14\% \\
\hline
3/5 of total & 7.17E+03 & 7.44E+03 & -3.84\% & 7.27E+03 & -1.50\% & 7.50E+03 & -4.71\% & 7.40E+03 & -3.32\% & 7.32E+03 & -2.08\% \\
\hline
4/5 of total & 7.17E+03 & 7.44E+03 & -3.84\% & 7.28E+03 & -1.55\% & 7.50E+03 & -4.70\% & 7.40E+03 & -3.31\% & 7.31E+03 & -2.06\% \\
\hline
5/5 of total & 7.17E+03 & 7.44E+03 & -3.85\% & 7.28E+03 & -1.53\% & 7.50E+03 & -4.70\% & 7.40E+03 & -3.29\% & 7.31E+03 & -2.06\% \\
\hline
\end{tabular}
}
\end{table}
\subsubsection{Streamline Body Results}

\begin{table}[H]
\centering
\caption{Complete data collected for streamline body simulation}
\label{tab:streamline_results}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\rowcolor{lightblue}
\textbf{Iteration} & \textbf{Expected (N)} & \textbf{Mesh 1 (N)} & \textbf{\% error} & \textbf{Mesh 2 (N)} & \textbf{\% error} & \textbf{Mesh 3 (N)} & \textbf{\% error} & \textbf{Mesh 4 (N)} & \textbf{\% error} & \textbf{Mesh 5 (N)} & \textbf{\% error} \\
\hline
1/5 of total & 2.45E+02 & 2.54E+02 & -3.51\% & 2.52E+02 & -2.77\% & 2.40E+02 & 2.04\% & 2.25E+02 & 8.16\% & 2.00E+02 & 18.44\% \\
\hline
2/5 of total & 2.45E+02 & 2.53E+02 & -3.40\% & 2.52E+02 & -2.73\% & 2.40E+02 & 1.93\% & 2.25E+02 & 8.05\% & 2.00E+02 & 18.56\% \\
\hline
3/5 of total & 2.45E+02 & 2.53E+02 & -3.45\% & 2.52E+02 & -2.79\% & 2.40E+02 & 2.02\% & 2.25E+02 & 8.10\% & 1.99E+02 & 18.58\% \\
\hline
4/5 of total & 2.45E+02 & 2.53E+02 & -3.40\% & 2.52E+02 & -2.83\% & 2.40E+02 & 1.88\% & 2.25E+02 & 8.11\% & 1.99E+02 & 18.60\% \\
\hline
5/5 of total & 2.45E+02 & 2.53E+02 & -3.45\% & 2.52E+02 & -2.81\% & 2.40E+02 & 1.86\% & 2.25E+02 & 8.11\% & 1.99E+02 & 18.59\% \\
\hline
\end{tabular}
}
\end{table}

\subsubsection{Long Cylinder Results}

\begin{table}[H]
\centering
\caption{Complete data collected for long cylinder simulation}
\label{tab:cylinder_results}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\rowcolor{lightblue}
\textbf{Iteration} & \textbf{Expected (N)} & \textbf{Mesh 1 (N)} & \textbf{\% error} & \textbf{Mesh 2 (N)} & \textbf{\% error} & \textbf{Mesh 3 (N)} & \textbf{\% error} & \textbf{Mesh 4 (N)} & \textbf{\% error} & \textbf{Mesh 5 (N)} & \textbf{\% error} \\
\hline
1/5 of total & 5.02E+03 & 5.12E+03 & -1.85\% & 5.17E+03 & -2.94\% & 5.01E+03 & 0.24\% & 5.28E+03 & -5.16\% & 5.28E+03 & -5.14\% \\
\hline
2/5 of total & 5.02E+03 & 5.11E+03 & -1.79\% & 5.19E+03 & -3.29\% & 5.02E+03 & 0.04\% & 5.28E+03 & -5.17\% & 5.28E+03 & -5.12\% \\
\hline
3/5 of total & 5.02E+03 & 5.14E+03 & -2.33\% & 5.19E+03 & -3.34\% & 5.04E+03 & -0.32\% & 5.28E+03 & -5.14\% & 5.28E+03 & -5.13\% \\
\hline
4/5 of total & 5.02E+03 & 5.13E+03 & -2.24\% & 5.19E+03 & -3.29\% & 5.04E+03 & -0.34\% & 5.28E+03 & -5.18\% & 5.28E+03 & -5.13\% \\
\hline
5/5 of total & 5.02E+03 & 5.12E+03 & -1.98\% & 5.19E+03 & -3.33\% & 5.04E+03 & -0.31\% & 5.28E+03 & -5.16\% & 5.28E+03 & -5.13\% \\
\hline
\end{tabular}
}
\end{table}
Some investigated objects (long cylinder/ stream line body) showed outliers where simulated results became more accurate with fewer iterations or decreasing mesh density. These are considered outliers because simulations continue until reaching most accurate results (the basis of residuals). When less dense meshes created more accurate results, this was likely caused by complex geometry modeling difficulties and insufficient boundary conditions. These outliers are excluded from final results.

\subsection{Overall Results Summary}

\begin{table}[H]
\centering
\caption{Summary of average iterations and mesh elements with corresponding errors across all simulations}
\label{tab:overall_summary}
\begin{tabular}{|c|c|c|c|c|}
\hline
\rowcolor{lightblue}
\textbf{Avg. Iterations}& \textbf{\% Error} & \textbf{Avg. Mesh Elements}& \textbf{\% Error} & \textbf{Time/Iteration (s)} \\
\hline
77 & 14.29\% & 114,025 & 14.40\% & 14 \\
\hline
154 & 11.42\% & 119,628 & 13.08\% & 14.5 \\
\hline
231 & 11.26\% & 133,739 & 13.51\% & 14 \\
\hline
308 & 11.24\% & 171,610 & 10.86\% & 15 \\
\hline
385 & 11.24\% & 308,837 & 7.61\% & 28.5 \\
\hline
\end{tabular}
\end{table}

Average time per iteration was recorded when simulations where done . Time per iteration correlates with mesh density, showing higher mesh density requires longer simulation time. Although generally the final iterations take less time and iterations don't all require equal time, averages were used without decimal precision since millisecond variations could be random and noisy.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{image6.png}
    \caption{Time versus average percentage error across all geometries}
    \label{fig:time_vs_error}
\end{figure}

When looking at the final results it is very clear that the simulations go on for a very long time, even if not allot of accuracy is gained, the function of increasing accuracy is assemptoting somewhere to 11 \%, and especially after the 3 hour mark not allot of accuracy is gained and allot of valuable energy is waisted. the experimental values where only to 3 significant figures a change in less than 0.02\% is not worth the time as it is insignificant to 3 significant figures, as a result instead of investing more than 10000 seconds on average for a simulaton only 4592 seconds would arguable give good enough results, this would more than half the time and save so much energy, reducing the accuracy for both variables by 0.01\% this means only 264 iterations on average is how long a simulation should run.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{image11.png}
\caption{Average amount of total iterations against average \% error}
\label{fig:iterations_final}
\end{figure}

whilst I found that 30234 mesh elements are sufficient for a volume of 1936m3.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{image2.png}
\caption{Average amount of mesh elements against average \% error}
\label{fig:mesh_final}
\end{figure}\textit{
The mesh density and amount of itterations is directly inversly correlated with % error, 
time is directy corrolated to itterations and mesh density, 
investing more time into the simulation will give significantly more accurate results at the start, and less signficantly more acurate results at the end.
it should be revised how long a simulation should urun for until it is unnesacary.}


\section{Improvements}

I have tried to apply my findings on real world use cases, I tried to simulate the drag experienced by a tesla modes s plaid as it had a publicly known very low drag coefficient. Unfortunately my computer could not handle the complexity that a car has so I could not find if my results can be used in the real world, next time I would want to try out if it works for engineers aswell. 

Unfortunately some of the geometries which I had experimental data to test against were described very badly like a long cylinder and streamline body, next time I would try and get my own experimental data to be sure that both have the same boundary conditions.

\section{References}

\textit{- Citing academic papers, CFD textbooks, and engineering articles.}

Assets:

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{image3.png}
\caption{Additional simulation visualization 1}
\label{fig:asset1}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{image10.png}
\caption{Additional simulation visualization 2}
\label{fig:asset2}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{image16.png}
\caption{Additional simulation visualization 3}
\label{fig:asset3}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{image13.png}
\caption{Extra pictures depicting that I actually did the simulations}
\label{fig:asset4}
\end{figure}

\end{document}
